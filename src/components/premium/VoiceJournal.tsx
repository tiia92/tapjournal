
import React, { useState, useRef, useEffect } from 'react';
import { Mic, StopCircle, Trash2, Play, Pause } from 'lucide-react';
import { useAuth } from '@/context/AuthContext';
import { Button } from '@/components/ui/button';
import { toast } from 'sonner';
import { useJournal } from '@/context/JournalContext';

interface VoiceJournalProps {
  entryId?: string;
  audioUrl?: string;
  transcription?: string;
}

const VoiceJournal: React.FC<VoiceJournalProps> = ({ entryId, audioUrl: existingAudioUrl, transcription }) => {
  const { user } = useAuth();
  const { saveAudioToEntry } = useJournal();
  const isPremium = user?.isPremium || false;
  const [isRecording, setIsRecording] = useState(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(existingAudioUrl || null);
  const [isPlaying, setIsPlaying] = useState(false);
  const [transcriptionText, setTranscriptionText] = useState(transcription || '');
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  useEffect(() => {
    // Create an audio element for controlling playback
    const audioElement = new Audio();
    audioElementRef.current = audioElement;
    
    audioElement.addEventListener('ended', () => {
      setIsPlaying(false);
    });
    
    // Set the source if there is an existing audio URL
    if (existingAudioUrl) {
      audioElement.src = existingAudioUrl;
    }
    
    return () => {
      audioElement.pause();
      audioElement.src = '';
    };
  }, [existingAudioUrl]);

  useEffect(() => {
    if (audioUrl) {
      audioElementRef.current!.src = audioUrl;
    }
  }, [audioUrl]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/mp3' });
        const audioUrl = URL.createObjectURL(audioBlob);
        setAudioBlob(audioBlob);
        setAudioUrl(audioUrl);
        
        // Save to the entry
        if (entryId) {
          // In a real app, you would upload the blob to storage and get a permanent URL
          // For demo purposes, we'll just use the object URL, which will be lost on page refresh
          saveAudioToEntry(entryId, audioUrl);
          
          // Simple mock of transcription - in a real app, you would use a transcription service
          setTimeout(() => {
            const mockTranscription = "This is a mock transcription. In a real app, this would be generated by a transcription service using the audio recording.";
            setTranscriptionText(mockTranscription);
            saveAudioToEntry(entryId, audioUrl, mockTranscription);
          }, 1500);
        }
      };

      mediaRecorder.start();
      setIsRecording(true);
      toast.info('Recording started');
    } catch (error) {
      console.error('Error accessing microphone:', error);
      toast.error('Could not access microphone. Please check permissions.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      
      // Stop all tracks on the stream
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
      toast.success('Recording saved');
    }
  };

  const clearRecording = () => {
    if (audioUrl) {
      URL.revokeObjectURL(audioUrl);
    }
    setAudioBlob(null);
    setAudioUrl(null);
    setTranscriptionText('');
    
    // Clear from the entry
    if (entryId) {
      saveAudioToEntry(entryId, '', '');
    }
  };

  const togglePlayback = () => {
    if (!audioElementRef.current || !audioUrl) return;
    
    if (isPlaying) {
      audioElementRef.current.pause();
      setIsPlaying(false);
    } else {
      audioElementRef.current.play();
      setIsPlaying(true);
    }
  };

  if (!isPremium) {
    return (
      <div className="tap-card flex flex-col items-center justify-center py-8 bg-muted/30">
        <Mic className="w-10 h-10 text-muted-foreground mb-2" />
        <h3 className="text-lg font-medium">Voice Journal</h3>
        <p className="text-sm text-muted-foreground text-center mt-1 max-w-sm">
          Record voice notes to capture your thoughts and feelings
        </p>
        <div className="text-primary text-sm mt-4">
          Premium Feature
        </div>
      </div>
    );
  }

  return (
    <div className="tap-card">
      <h3 className="text-lg font-medium mb-2">Voice Journal</h3>
      <p className="text-sm text-muted-foreground mb-4">Record voice notes for your journal</p>
      
      <div className="flex flex-col space-y-4">
        {isRecording ? (
          <div className="flex items-center justify-center bg-red-50 p-4 rounded-lg animate-pulse">
            <div className="text-red-500 font-medium flex items-center">
              <span className="mr-2">Recording in progress</span>
              <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse"></div>
            </div>
          </div>
        ) : audioUrl ? (
          <div className="bg-muted/30 p-4 rounded-lg">
            <div className="flex space-x-2 mb-3">
              <Button variant="outline" size="sm" onClick={togglePlayback} className="flex-1">
                {isPlaying ? <Pause className="w-4 h-4 mr-1" /> : <Play className="w-4 h-4 mr-1" />}
                {isPlaying ? 'Pause' : 'Play'}
              </Button>
              <Button variant="outline" size="sm" onClick={clearRecording} className="flex-1">
                <Trash2 className="w-4 h-4 mr-1" /> Delete
              </Button>
            </div>
            
            {transcriptionText && (
              <div className="mt-3 p-3 bg-secondary/50 rounded-md text-sm">
                <h4 className="font-medium mb-1">Transcription:</h4>
                <p className="text-muted-foreground">{transcriptionText}</p>
              </div>
            )}
          </div>
        ) : (
          <div className="flex justify-center">
            <Button 
              onClick={startRecording} 
              variant="outline" 
              size="lg" 
              className="w-20 h-20 rounded-full flex items-center justify-center"
            >
              <Mic className="w-8 h-8 text-primary" />
            </Button>
          </div>
        )}
        
        {isRecording && (
          <Button 
            onClick={stopRecording} 
            variant="destructive" 
            className="flex items-center justify-center"
          >
            <StopCircle className="w-4 h-4 mr-2" /> Stop Recording
          </Button>
        )}
      </div>
    </div>
  );
};

export default VoiceJournal;
